{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "colab": {
   "name": "Exercício - Planejamento de Experimentos.ipynb",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CI8fNbys1WIN",
    "colab_type": "text"
   },
   "source": [
    "# Exercício 05\n",
    "## Planejamento de Experimentos\n",
    "### Alunos:\n",
    "\n",
    " - Guilherme Michel Lima de Carvalho 11175052\n",
    " - Jaqueline Lopes Dias 11551472\n",
    " - Marcos Jardel Henriques 10357438\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ae7mLCZI-DjC",
    "colab_type": "text"
   },
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugQ3MbYx99I-",
    "colab_type": "text"
   },
   "source": [
    "## Objetivos da prática:\n",
    "- Entender modelagem de dados;\n",
    "- Entender o processo de avaliação;\n",
    "- Trabalhar com procedimentos de amostragem;\n",
    "- Trabalhar com várias medidas de avaliação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6lfIEgb1WIQ",
    "colab_type": "text"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Funções novas utilizadas no exercício\n",
    "\n",
    "- [sklearn.metrics.confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html?highlight=confusion_matrix#sklearn.metrics.confusion_matrix)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GD84PKIi1WIR",
    "colab_type": "text"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Escolha, entre as opções abaixo, apenas UM dataset para realizar os exercícios.**\n",
    "\n",
    "**Se o dataset escolhido tiver mais de duas classes, transforme ele num problema binário. Isso pode ser feito escolhendo uma classe para representar a classe positiva e o restante a classe negativa.**\n",
    "\n",
    "**Possíveis datasets:**\n",
    "\n",
    "\n",
    "*   **Câncer de mama:** [sklearn.datasets.load_breast_cancer](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer)\n",
    "*   **Wine:** [sklearn.datasets.load_wine](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Após a análise dos dados e um pré-processamento vem a etapa de modelagem dos experimentos. Essa etapa pode requerer voltar no pré-processamento caso perceba-se que algo precisa ser feito. A modelagem visa determinar as etapas da execução dos experimentos. No nosso cenário, experimento é a utilização de algoritmos de classificação, regressão ou agrupamento. Para tanto, é preciso definir, com ajuda da análise dos dados, o tipo do problema (classificação, regressão, ...), os atributos/features a serem utilizados e o processo de avaliação.\n",
    "\n",
    "Essa prática foca mais no processo de avaliação.\n",
    "Para a avaliação é preciso definir qual a função de custo/erro adequada, e qual o estimador para o desempenho.\n",
    "\n",
    "Utilizaremos medidas de desempenho para classificação binária baseadas na matriz de confusão (TFP, TFN, TVP, TVN).\n",
    "\n",
    "Nas aplicações reais, o cliente dita qual a medida de desempenho deve ser utilizada, e muitas vezes não é uma das clássicas. E como essa medida, em geral, tem um impacto grande no treinamento do algoritmo de classificação, muitas vezes o algoritmo precisa ser adaptado e isso não é uma tarefa fácil.\n",
    "\n",
    "Após a definição do tipo do problema e da medida de avaliação, é preciso definir como será estimado o desempenho final.\n",
    "\n",
    "Esse processo está ligado á escolha do algoritmo de classificação bem como a escolha de alguns hiperparâmetros. Uma abordagem muito comum na área é a utilização do 10-fold Cross-Validation. Esse procedimento pode ser utilizado para estimar o desempenho do classificador final, bem como, na escolha de alguns poucos hiperparâmetros.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-DsLbxZc8sDL",
    "colab_type": "text"
   },
   "source": [
    "### Questão 01.\n",
    "\n",
    "Dada a introdução acima, já definimos que o tipo do problema é classificação. Defina quais os atributos você utilizará, e a medida de avaliação você acha adequada e explique o porquê dessas escolhas. Você também deve fazer nessa questão os pré-processamentos que achar necessário.\n",
    "\n",
    "Lembre-se que o objetivo da classificação é fazer predições para dados não vistos, ou seja, quando o algoritmo for colocado em produção ele classificará corretamente amostras não vistas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRDthSyd90j4",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "De acordo com o repositório\n",
    "[UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)\n",
    "temos as seguinte variáveis no dataset:\n",
    "\n",
    "**Attribute Information:**\n",
    "\n",
    "1) ID number\n",
    "\n",
    "2) Diagnosis (M = malignant, B = benign)\n",
    "3-32)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "a) radius (mean of distances from center to points on the perimeter)\n",
    "\n",
    "b) texture (standard deviation of gray-scale values)\n",
    "\n",
    "c) perimeter\n",
    "\n",
    "d) area\n",
    "\n",
    "e) smoothness (local variation in radius lengths)\n",
    "\n",
    "f) compactness (perimeter^2 / area - 1.0)\n",
    "\n",
    "g) concavity (severity of concave portions of the contour)\n",
    "\n",
    "h) concave points (number of concave portions of the contour)\n",
    "\n",
    "i) symmetry\n",
    "\n",
    "j) fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "\n",
    "Portanto, dada essas features o objetivo é prever se a pessoa tem o cancer de mama ou não.\n",
    "Primeiramente, vejamos uma análise exploratória dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "features, target = load_breast_cancer(return_X_y=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(features)\n",
    "print(target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['malignant', 'benign'], dtype='<U9')"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n       'mean smoothness', 'mean compactness', 'mean concavity',\n       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n       'radius error', 'texture error', 'perimeter error', 'area error',\n       'smoothness error', 'compactness error', 'concavity error',\n       'concave points error', 'symmetry error',\n       'fractal dimension error', 'worst radius', 'worst texture',\n       'worst perimeter', 'worst area', 'worst smoothness',\n       'worst compactness', 'worst concavity', 'worst concave points',\n       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Questão 02.\n",
    "Uma boa prática é escolher modelos mais simples, dados dois modelos com desempenho similar a escolha do mais simples é indicada pois com isso há algumas garantias de melhor generalização. Generalização, de maneira geral, é a propriedade que garante que o classificador terá desempenho parecido ao reportado no teste.\n",
    "\n",
    "A definição da complexidade de um modelo nem sempre é uma tarefa fácil. Uma maneira de tentar mensurar isso é através do número de parâmetros do modelo, do tipo de função que ele implementa (linear ou não linear, cortes ortogonais no espaço, ...), ou da chamada dimensão VC (Vapnik-Chervonenkis) do classificador. A dimensão VC é um tópico mais avançado e faz parte da chamada teoria do aprendizado estatístico, ela é citada aqui apenas como curiosidade não é esperado que saibem sobre isso.\n",
    "\n",
    "Execute a função *classificacao* definida no notebook com a medida de desempenho que você definiu. Diga qual o modelo tem o melhor desempenho e explique porque você acha isso."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WaR7HyvO9zss",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy import mean, std\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def classificacao(data, columns, target, score=balanced_accuracy_score, score_name='acurácia', \n",
    "                  folds=5, plot=True):\n",
    "    \"\"\"\n",
    "    Executa classificação do conjunto de dados passado\n",
    "    ---------------------------------------------------------------\n",
    "    data:       DataFrame. Conjunto de dados\n",
    "    columns:    Lista de inteiros. Índice das colunas utilizadas no treinamento e teste\n",
    "    target:     Inteiro. Índice da coluna alvo\n",
    "    score:      Função. A função que calcula a medida de desempenho desejada. Deve ser uma \n",
    "                função que compara dois vetores, o primeiro vetor são os valores preditos\n",
    "                pelo classificador, o segundo os rótulos reais\n",
    "                Vide exemplo das funções em \n",
    "                http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "                como por exemplo, sklearn.metrics.accuracy_score\n",
    "                http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "    score_name: String. Uma string com o nome da medida de desempenho\n",
    "    folds:      Inteiro. Número de folds na validação cruzada\n",
    "    plot:       Booleano. True para plotar os gráficos False para não plotar\n",
    "    ---------------------------------------------------------------\n",
    "    Realiza a classificação em 6 modelos (perceptron, \n",
    "    SVM com kernel polinomial de grau 3, Árvore de decisão, 3NN, 5NN, e 7NN)\n",
    "    Plot o gráfico de desempenho para cada classificador.\n",
    "    Retorna um dicionário com os classificadores treinados, as medidas de desempenho e matriz de confusão\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    # inicializa os modelos com os parâmetros solicitados\n",
    "    prcp = Perceptron()\n",
    "    svm_n = SVC(C=10*len(data), kernel='poly', degree=3, gamma=1, coef0=1, cache_size=500, max_iter=1e6)\n",
    "    dt = DecisionTreeClassifier(criterion='gini', splitter='best', min_samples_split=int(len(data)*0.1))\n",
    "    _3nn = KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='auto')\n",
    "    _5nn = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto')\n",
    "    _7nn = KNeighborsClassifier(n_neighbors=7, weights='uniform', algorithm='auto')\n",
    "    \n",
    "    clfs = [prcp, svm_n, dt, _3nn, _5nn, _7nn]\n",
    "    clfs_names = ['perceptron', 'svm_poly', 'dt', '3nn', '5nn', '7nn']\n",
    "    \n",
    "    #Inicializa estruturas para matrizes de confusão \n",
    "    confusion_matrices = {\n",
    "        'perceptron':np.array([[0,0],[0,0]]),\n",
    "        'svm_poly':np.array([[0,0],[0,0]]),\n",
    "        'dt':np.array([[0,0],[0,0]]),\n",
    "        '3nn':np.array([[0,0],[0,0]]),\n",
    "        '5nn':np.array([[0,0],[0,0]]),\n",
    "        '7nn':np.array([[0,0],[0,0]])\n",
    "    }\n",
    "\n",
    "    # prepara validação cruzada\n",
    "    # faz divisão do dataset em fold partes\n",
    "    cv = KFold(n_splits=folds, shuffle=True)\n",
    "    \n",
    "    # itera para cada classificador fazendo treino e teste\n",
    "    results = {'perceptron':[], 'svm_poly':[], 'dt':[], '3nn':[], '5nn':[], '7nn':[]}\n",
    "    for c, c_name in zip(clfs, clfs_names):\n",
    "        for train_index, test_index in cv.split(data):\n",
    "            \n",
    "            # separa conjunto de treino e de teste\n",
    "            x_train, y_train = data.iloc[train_index, columns], data.iloc[train_index, target]\n",
    "            x_test, y_test = data.iloc[test_index, columns], data.iloc[test_index, target]\n",
    "            \n",
    "            # faz o treino do modelo\n",
    "            clf = c.fit(X=x_train, y=y_train)\n",
    "            \n",
    "            # valores predito pelo classificador\n",
    "            y_pred = clf.predict(x_test)\n",
    "            # rótulos verdadeiros convertidos para array\n",
    "            y_test = np.array(y_test)\n",
    "            \n",
    "            # realiza predição no conjunto de teste e salva o resultado\n",
    "            results[c_name].append( score(y_test, y_pred) )\n",
    "            confusion_matrices[c_name] += confusion_matrix(y_test, y_pred)        \n",
    "    \n",
    "    if not plot:\n",
    "        return {'results': results, 'clfs':clfs}\n",
    "    # faz o plot de desempenho dos classificadores\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.bar(range(1, len(clfs)+1), [mean(results[name]) for name in clfs_names], \n",
    "                                yerr=[std(results[name]) for name in clfs_names])\n",
    "    plt.xticks(range(1, len(clfs)+1), clfs_names, rotation=45)\n",
    "    title = 'Desempenho dos classificadores - %s'%(score_name)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "    return {'results': results, 'clfs':clfs, 'confusion_matrices': confusion_matrices}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YiDHzc6ikoyz",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njxCEyHt9BH6",
    "colab_type": "text"
   },
   "source": [
    "---\n",
    "\n",
    "### Questão 03.\n",
    "\n",
    "Utilizar os 3 procedimentos de amostragem para estimação do desempenho:\n",
    "- 10-fold Cross Validation;\n",
    "- Leave-one-out;\n",
    "- Boostrap (1000 amostras de boostrap).\n",
    "\n",
    "Para o dataset escolhido, executar os 3 procedimentos acima para estimar o desempenho. Avalie a diferença na variância entre essas abordagens.\n",
    "\n",
    "  * Para o 10-fold Cross Validation e o leave-one-out, você pode utilizar a função *classificacao* já disponível apenas ajustando o parâmetro *folds*.\n",
    "  * Já para o boostrap, você vai precisar implementar a função classificação modificada `classificacao_bootstrap`. A seção de interesse que vocês precisarão modificar está destacada na função. No cálculo do bootstrap utilize 80% do dataset para treino e 20% para teste.\n",
    "\n",
    "Essas execuções podem demorar um pouco, então tenham paciência.\n",
    "\n",
    "**No material complementar há exemplos de como fazer o bootstrap**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "M2wJGs-fDZpw",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy import mean, std\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def classificacao_bootstrap(data, columns, target, score=balanced_accuracy_score, no_bs=1000, p_teste=0.2, score_name='acurácia', plot=True):\n",
    "    \"\"\"\n",
    "    Executa classificação do conjunto de dados passado\n",
    "    ---------------------------------------------------------------\n",
    "    data:       DataFrame. Conjunto de dados\n",
    "    columns:    Lista de inteiros. Índice das colunas utilizadas no treinamento e teste\n",
    "    target:     Inteiro. Índice da coluna alvo\n",
    "    score:      Função. A função que calcula a medida de desempenho desejada. Deve ser uma \n",
    "                função que compara dois vetores, o primeiro vetor são os valores preditos\n",
    "                pelo classificador, o segundo os rótulos reais\n",
    "                Vide exemplo das funções em \n",
    "                http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "                como por exemplo, sklearn.metrics.accuracy_score\n",
    "                http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "    no_bs:      Número de repetições do bootstrap\n",
    "    p_teste:    Porcentagem para teste da amostra do bootstrap\n",
    "    score_name: String. Uma string com o nome da medida de desempenho    \n",
    "    plot:       Booleano. True para plotar os gráficos False para não plotar\n",
    "    ---------------------------------------------------------------\n",
    "    Realiza a classificação em 6 modelos (perceptron, \n",
    "    SVM com kernel polinomial de grau 3, Árvore de decisão, 3NN, 5NN, e 7NN)\n",
    "    Plot o gráfico de desempenho para cada classificador.\n",
    "    Retorna um dicionário com os classificadores treinados, medidas de desempenho e matriz de confusão\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    # inicializa os modelos com os parâmetros solicitados\n",
    "    prcp = Perceptron()\n",
    "    svm_n = SVC(C=10*len(data), kernel='poly', degree=3, gamma=1, coef0=1, cache_size=500, max_iter=1e6)\n",
    "    dt = DecisionTreeClassifier(criterion='gini', splitter='best', min_samples_split=int(len(data)*0.1))\n",
    "    _3nn = KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='auto')\n",
    "    _5nn = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto')\n",
    "    _7nn = KNeighborsClassifier(n_neighbors=7, weights='uniform', algorithm='auto')\n",
    "    \n",
    "    clfs = [prcp, svm_n, dt, _3nn, _5nn, _7nn]\n",
    "    clfs_names = ['perceptron', 'svm_poly', 'dt', '3nn', '5nn', '7nn']\n",
    "    confusion_matrices = {\n",
    "        'perceptron':np.array([[0,0],[0,0]]),\n",
    "        'svm_poly':np.array([[0,0],[0,0]]),\n",
    "        'dt':np.array([[0,0],[0,0]]),\n",
    "        '3nn':np.array([[0,0],[0,0]]),\n",
    "        '5nn':np.array([[0,0],[0,0]]),\n",
    "        '7nn':np.array([[0,0],[0,0]])\n",
    "    }\n",
    "    \n",
    "    # itera para cada classificador fazendo treino e teste\n",
    "    results = {'perceptron':[], 'svm_poly':[], 'dt':[], '3nn':[], '5nn':[], '7nn':[]}\n",
    "    for c, c_name in zip(clfs, clfs_names):\n",
    "      for i in range(0, no_bs):\n",
    "        ################# IMPLEMENTE ABAIXO O BOOTSTRAP #######################\n",
    "        #    Sua implementação deve fazer o append no vetor results da mesma \n",
    "        #    forma que a implementação original faz.\n",
    "        #    Dentro desse loop:\n",
    "        #     c: variável-objeto que representa o classificador\n",
    "        #     c_name: Nome do classificador\n",
    "        #     results: vetor de resultado\n",
    "        #######################################################################\n",
    "\n",
    "\n",
    "\n",
    "        #######################################################################\n",
    "        \n",
    "    if not plot:\n",
    "        return {'results': results, 'clfs':clfs}\n",
    "    # faz o plot de desempenho dos classificadores\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.bar(range(1, len(clfs)+1), [mean(results[name]) for name in clfs_names], \n",
    "                                yerr=[std(results[name]) for name in clfs_names])\n",
    "    plt.xticks(range(1, len(clfs)+1), clfs_names, rotation=45)\n",
    "    title = 'Desempenho dos classificadores - %s'%(score_name)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "    return {'results': results, 'clfs':clfs, 'confusion_matrices': confusion_matrices}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ENLXredtknpo",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIT-mDF49RUD",
    "colab_type": "text"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Questão 04.\n",
    "\n",
    "Utilizando o 10-fold cross validation, calcule as medidas de avaliação baseadas na matriz de confusão (TFP, TFN, TVN, TVP). Como em meio a tantas medidas de avaliação, comparar os classificadores? Como escolher o melhor?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Bey7Lbpkkl_-",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}